---
title: "<span style='color:#f10f10f10; font-size:100pt'><br>
SLOPE for Count Responses
</span>"
subtitle: "<span style='color:#f10f10f10; font-size:30pt'>
 </span>"
author: "<span style='color:#f10f10f10; font-size:30pt'></span>"
---

```{r message=FALSE, warning=FALSE, include=FALSE}
# Setup ----
## Packages to use ----
pacman::p_load(tidyverse, janitor, writexl, 
              readxl, scales, ggdist, 
              distributional)

## Set theme ------
# theme_set(theme_jmr(text = element_text(family = "Lato",
#                                         size=25),
#                     panel.grid = element_blank(),
#                     plot.title = formt_text(size = 35)))
# 
# options(ggplot2.discrete.colour = c("#1E81A2", "#FF483B", "#039176", "#FFAC41"),
#         ggplot2.discrete.fill = c("#1E81A2", "#FF483B", "#039176", "#FFAC41"))

## Specify locale ----
Sys.setlocale("LC_ALL", "UTF-8")

## Disable scientific notation ----
options(scipen = 999)
```


## Refining the Research Focus

* **Initial Research Direction:** Explore proposed penalization by Zilberman & Abramovich (2025).

* **Problem:** The proposed method relies on Lasso and SLOPE as convex surrogates.

* **Refined Project Focus:** This project centers specifically on **SLOPE's (Sorted L-One Penalized Estimation)** performance for **count data**.

---

## Paper Ideas

Lorem ipsum dolor sit amet: 

* consectetur **adipiscing elit**, 
* sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. 
* Ut enim ad minim veniam, quis nostrud exercitation

---

## Experiments

Lorem ipsum dolor sit amet: 

* consectetur **adipiscing elit**, 
* sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. 
* Ut enim ad minim veniam, quis nostrud exercitation

---

## Experimental Design: Proposal

* **Research Gap:** Original SLOPE paper (Bogdan et al., 2015) focused on linear models / Gaussian errors[cite: 1].
* **Goal:** Compare SLOPE against other penalized methods (Lasso, Adaptive Lasso) via simulations specifically for count responses (Poisson model).
* **Research Question:** How does the performance of SLOPE regarding variable selection accuracy (FDR and Power) compare to Lasso and Adaptive Lasso when applied to high-dimensional Poisson regression?

## Compared Methods & Penalties

* **Objective:** Minimize $- \frac{1}{n} \log L(\beta; y, X) + \text{Penalty}(\beta)$
* **Penalties:**
    * **SLOPE Penalty:** $\sum_{i=1}^{p}\lambda_{i}|\beta|_{(i)}$, $|\beta|_{(1)} \ge ... \ge |\beta|_{(p)}$, $\lambda_1 \ge ... \ge \lambda_p \ge 0$.
    * **Lasso (L1):** $\lambda ||\beta||_{1}$
    * **Adaptive Lasso:** $\lambda \sum_{j=1}^{p} w_j |\beta_j|$ (where $w_j \propto 1/|\hat{\beta}_{init, j}|^\gamma$)


## Experimental Design: Data Generation

* **Model:** Poisson Regression
    * $Y_i \sim \text{Poisson}(\lambda_i)$
    * $\log(\lambda_i) = \beta_0 + X_i \beta$ 
* **Dimensions:** $n = 1000$ observations.
    * $p = 500$ (p < n)
    * $p = 1000$ (p = n)
    * $p = 2000$ (p > n)
* **Replications:** R = 50 runs per setting.

## Experimental Design: Predictors (X)

* **Generation:** $X_{ij} \sim N(0, 1)$, columns standardized.
* **Correlation Structures:**
    * Independent: $\rho = 0$ 
    * Moderate: $\rho = 0.5$ 
    * High: $\rho = 0.8$ 
    
## Experimental Design: True $\beta$

* **Sparsity $k = ||\beta||_0$:** 
    * $k = 10$
    * $k = 20$
    * $k = 50$
    * $k = 100$
* **Signal Strength:** 
    * Simulate "Weak" $\beta$ scenarios.
    * Simulate "Strong" $\beta$ scenarios.

## Experimental Design: Parameter Tuning

* **Lasso, Adaptive Lasso:**
    * 10-fold Cross-Validation.
    * Select tuning parameter(s) by minimizing Poisson deviance.
    * *(Specify initial estimator and $\gamma$ for Adaptive Lasso)*
* **SLOPE:**
    * Target FDR level $q = 0.1$.
    * Use BH-inspired sequence $\{\lambda_i\}$.

## Experimental Design: Evaluation Metrics

* **False Discovery Rate.**
* **Power.**
